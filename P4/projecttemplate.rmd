Brazilian Consumer Complaints by Luiz Gerosa
========================================================

```{r echo=FALSE, message=FALSE, warning=FALSE, packages}
# Load all of the packages that you end up using in your analysis in this code
# chunk.

# Notice that the parameter "echo" was set to FALSE for this code chunk. This
# prevents the code from displaying in the knitted HTML output. You should set
# echo=FALSE for all code chunks in your file, unless it makes sense for your
# report to show the code that generated a particular plot.

# The other parameters for "message" and "warning" should also be set to FALSE
# for other code chunks once you have verified that each plot comes out as you
# want it to. This will clean up the flow of your report.

library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, Load_the_Data}
# Load the Data
Sys.setlocale(category = "LC_ALL", locale = "pt_BR.UTF-8")
ds = read.csv("data/reclamacoes-fundamentadas-sindec-2015.csv", 
              sep=';', encoding='utf-8', stringsAsFactors = FALSE, strip.white = TRUE)

# keeping only columns used in this analysis
ds <- subset(ds, select=c(AnoCalendario, DataArquivamento, DataAbertura, UF,
                          strRazaoSocial, Tipo,
                          Atendida, DescricaoProblema, SexoConsumidor,
                          FaixaEtariaConsumidor))

# renaming columns
names(ds) <- c('year', 'closingDate', 'registerDate', 'state', 'companyName',
               'type', 'resolved', 'issue', 'gender', 'age')

# replacing empty cells with NA
ds[ds == ''] <- NA
ds[ds == 'NULL'] <- NA
ds$gender[ds$gender == 'N'] <- NA

# removing rows with any missing value (NA)
ds <- na.omit(ds)

# keeping only complaints of companies (type == 1)
ds <- ds[ds$type == 1,]
ds$type <- NULL

# fixing data types
ds$closingDate <- as.Date(ds$closingDate)
ds$registerDate <- as.Date(ds$registerDate)
ds$state <- as.factor(ds$state)
ds$companyName <- as.factor(ds$companyName)
ds$resolved <- as.factor(ds$resolved)
ds$gender <- as.factor(ds$gender)
ds$age <- as.factor(ds$age)
ds$issue <- as.factor(ds$issue)

# translating age ranges
ds$age <- recode(ds$age,
                 `até 20 anos` = '<20',
                 `entre 21 a 30 anos` = '21 to 30',
                 `entre 31 a 40 anos` = '31 to 40',
                 `entre 41 a 50 anos` = '41 to 50',
                 `entre 51 a 60 anos` = '51 to 60',
                 `entre 61 a 70 anos` = '61 to 70',
                 `mais de 70 anos` = '>70',
                 `Nao Informada` = 'not informed')

# translating S (sim) to Y (yes)
ds$resolved <- recode(ds$resolved, S = 'Y', N = 'N')

# creating a new continuous variable
ds$elapsedDays <- as.numeric(ds$closingDate - ds$registerDate)

# cleaning wrong chars
ds$companyName <- sub('[@|\\.]$', '', ds$companyName)

# very basic normalizations of company types
ds$companyName <- sub('S[\\.|\\/]+A.*$', 'S/A', ds$companyName)
ds$companyName <- sub('LTDA*$', 'LTDA', ds$companyName)

# fix typos for most frequent companies
ds$companyName <- sub('SERVICOS', 'SERVIÇOS', ds$companyName)
ds$companyName <- sub('ECONOMICA', 'ECONÔMICA', ds$companyName)
ds$companyName <- sub('COMUNICA[C|Ç][A|Ã]O', 'COMUNICAÇÃO', ds$companyName)
ds$companyName <- sub('COMUNICACOES', 'COMUNICAÇÕES', ds$companyName)
ds$companyName <- sub('- CEF$', '', ds$companyName)
ds$companyName <- sub('^OI.+S/A$', 'OI S/A', ds$companyName)

ds$companyName <- str_trim(ds$companyName)

```

# Introduction
When Brazilian consumers need to resolve a dispute with business the first step 
is to go to a local Procon (Consumer Protection Agency) and file a complaint.
The Procon assists the consumer and intermediates the resolution with the
company

# DataSet Overview

The [dataset](http://dados.gov.br/dataset/cadastro-nacional-de-reclamacoes-fundamentadas-procons-sindec1)
used in this analysis contains information about complaints made in 2015 and it
was download from official Brazilian government open data website: http://dados.gov.br. 


```{r echo=FALSE, results = 'asis'}
kable(head(ds))
```

### Summary
```{r echo=FALSE}
summary(ds)
```

### Top 10 most common complaints (in Portugues)
```{r echo=FALSE}
issueFrequency <- count(ds, issue)
issueFrequency <- arrange(issueFrequency, desc(n))
kable(head(issueFrequency, 10))
```

### Top 10 most frequent companies
```{r echo=FALSE}
top_companies <- count(ds, companyName)
top_companies <- arrange(top_companies, desc(n))
kable(head(top_companies, 10))
```

# Univariate Plots Section

```{r echo=FALSE}
# calculate the frequency table for the resolved feature
resolved <- ds %>%
  group_by(resolved) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

resolutionRate <- as.double(resolved[2, 'freq'])
pct <- paste(round(resolved$freq * 100), '%', sep = '')

pie(resolved$freq, paste(resolved$resolved, pct, sep = ' - '))
```

The resolution rate is about 65%.

```{r echo=FALSE}
# calculate the frequency table for the gender feature
gender <- ds %>%
  group_by(gender) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

man_rate = as.double(gender[2, 'freq'])
  
pct <- paste(round(gender$freq * 100), '%', sep = '')
pie(gender$freq, paste(gender$gender, pct, sep = ' - '))
```

54% of complaints came from women vs 46% from men.

```{r echo=FALSE}
qplot(x = ds$state, data = ds)
```

The state with most complaints is São Paulo (SP).

```{r echo=FALSE}
qplot(x = ds$age, data = ds)
```

Most complaints are made by people between 31 and 40 years old.

```{r echo=FALSE, warning=FALSE}
ggplot(aes(x = elapsedDays), data = ds) +
  geom_histogram(binwidth = 40)
```

The number of days to close an issue has a long tail.

```{r echo=FALSE, warning=FALSE}
ggplot(aes(x = '', y = elapsedDays), data = ds) +
  geom_boxplot() 
```

The number of days to close an issue has many outliers (11%).

```{r echo=FALSE, warning=FALSE}
boxplot_stats <- boxplot.stats(ds$elapsedDays)
length(boxplot_stats['out'][[1]]) / boxplot_stats['n'][[1]]
```

# Univariate Analysis

### What is the structure of your dataset?

After cleaning missing values, removing columns not used in this analysis and 
adding a new one, the dataset contains around 221k complaints and 10 variables.

```{r}
dim(ds)
```

### What is/are the main feature(s) of interest in your dataset?

The main feature is _"resolved"_ which indicates if the complaint was resolved
with the company.

### What other features in the dataset do you think will help support your \
investigation into your feature(s) of interest?

Categorical features like gender, state, age, etc.

### Did you create any new variables from existing variables in the dataset?

Yes. I calculated the elapsed time in days between the registration date and the
closing date.

### Of the features you investigated, were there any unusual distributions? \
Did you perform any operations on the data to tidy, adjust, or change the form \
of the data? If so, why did you do this?

I did some basic data wrangling in the company name so it can be counted correctly.

# Bivariate Plots Section

```{r echo=FALSE, Bivariate_Plots}

# calculate the frequency table for the gender / resolved features
gender_resolved <- ds %>%
  group_by(gender, resolved) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

ggplot(gender_resolved, aes(x = gender, y = freq, fill = factor(resolved))) +
  geom_bar(stat="identity") +
  geom_hline(yintercept = resolutionRate)
```

Men and women have practically the same chance to have their issues resolved.

```{r echo=FALSE}

# calculate the frequency table for the state / resolved features
state_resolved <- ds %>%
  group_by(state, resolved) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

ggplot(state_resolved, aes(x = state, y = freq, fill = factor(resolved))) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = resolutionRate)
```

Consumers in some states have a much higher chance to resolve their issues.

```{r echo=FALSE}

# calculate the frequency table for the age / resolved features
age_resolved <- ds %>%
  group_by(age, resolved) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

ggplot(age_resolved, aes(x = age, y = freq, fill = factor(resolved))) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = resolutionRate)
```

All age ranges have practically the same resolution rate around 65%, with a
small advantage to under 20 (68%) and over 70 (67%). When the age is not informed,
the resolution rate is smaller (~61%).

```{r echo=FALSE}

# calculate the resolution rate per company spreading the resolved
# feature into columns (N and Y)
company_resolved <- ds %>%
  group_by(companyName, resolved) %>%
  summarise (n = n()) %>%
  spread(resolved, n, fill = 0) %>%
  arrange(desc(N + Y)) %>%
  mutate(freq = Y / (N+Y))

kable(head(company_resolved, 10))
```

Resolution rate for the top 10 most frequent companies. OI S/A is the company
with most complaints but also has a very high resolution rate.

```{r echo=FALSE, warning=FALSE}
ggplot(ds, aes(x = elapsedDays, color = resolved)) +  
  geom_freqpoly(binwidth = 10) +
  scale_x_continuous(limits = c(0, 500), breaks = seq(0, 500, 20))
```

The shape of the distribution of the number of days to close an issue doesn't
change if the issue was resolved or not.

```{r echo=FALSE, warning=FALSE}

# create a new categorical variable: elapsed days intervals
ds$elapsedDaysIntervals <- cut( ds$elapsedDays, 
                                breaks = c(0, 25, 64, 10^4),
                                include.lowest = TRUE)

# calculate the frequency table for the elapsed days intervals
elapseDaysIntervals_resolved <- ds %>%
  group_by(elapsedDaysIntervals, resolved) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  arrange(desc(resolved), elapsedDaysIntervals)

ggplot(ds, aes(x = elapsedDays, color = resolved)) +  
  geom_density() +
  scale_x_continuous(limits = c(0, 200), breaks = seq(0, 200, 25))
```

The issue has a better chance to be resolved between 25 and 60 days after its
registration date. The resolution rate in this interval is 70%.

```{r echo=FALSE, warning=FALSE}
ggplot(aes(x = resolved, y = elapsedDays), data = ds) +
  geom_boxplot() +
  coord_cartesian(ylim = c(0, 500))
```

Resolved issues are closed more quickly than unresolved issues. The resolved issues
have a median of 75 days versus 93 days of unresolved issues.

```{r echo=FALSE, warning=FALSE}
by(ds$elapsedDays, ds$resolved, summary)
```

```{r echo=FALSE}

# calculate the frequency table for the state / gender features
state_gender <- ds %>%
  group_by(state, gender) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))

ggplot(state_gender, aes(x = state, y = freq, fill = factor(gender))) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = man_rate)
```

Women and men complaints per state are uniformly distributed.

```{r echo=FALSE}

# calculate the frequency table for the age / gender features
age_gender <- ds %>%
  group_by(age, gender) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  arrange(freq)

ggplot(age_gender, aes(x = age, y = freq, fill = factor(gender))) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = man_rate)
```

Women and men complaints per age interval are uniformly distributed.
Men do not inform their age more frequently than women (52% vs 48%).

# Bivariate Analysis

### Talk about some of the relationships you observed in this part of the \
investigation. How did the feature(s) of interest vary with other features in \
the dataset?

The resolution rate varies a lot depending on the state and the number of days
it takes to close the complaint.

### Did you observe any interesting relationships between the other features \
(not the main feature(s) of interest)?

The median time to resolve an issue varies a lot state by state. 

### What was the strongest relationship you found?

The state where the complaint was filed has a strong impact on the resolution
rate.

# Multivariate Plots Section

```{r echo=FALSE}

# calculate the median elapsed days per state and resolved features
state_resolved_elapsedays <- ds %>%
  group_by(state, resolved) %>%
  summarise(median = median(elapsedDays))

ggplot(state_resolved_elapsedays, aes(x = state, y = median)) +
  geom_bar(aes(fill = resolved), position = "dodge", stat = "identity")
```

The median time to close an issue in some states (e.g. AP, PB and TO)
have a huge difference when the issue was resolved or not.

```{r echo=FALSE}

# subseting to consider only resolved issues
state_resolved_elapsedays <- subset(state_resolved_elapsedays, (resolved == 'Y'))

ggplot(state_resolved_elapsedays, aes(x = state, y = median)) +
  geom_bar(aes(fill = resolved), position = "dodge", stat = "identity")
```

Observing only resolved issues, we can have a better sense of the median time 
to resolve an issue on different states. Some states have much worse median time
than others.

```{r echo=FALSE, warning=FALSE, message=FALSE}

medianElapsedDaysResolved <- median(ds[resolved == 'Y', 'elapsedDays'])

# joining the frequency table of states/resolved with the median elapsed days
state_resolved <- subset(state_resolved, (resolved == 'Y'))
state_resolvedrate_elapsedays <- state_resolved_elapsedays %>%
  left_join(state_resolved)

ggplot(state_resolvedrate_elapsedays, aes(x = freq, y = median, label = state)) +
  geom_vline(xintercept = resolutionRate, linetype = "dashed") +
  geom_hline(yintercept = medianElapsedDaysResolved, linetype = "dashed") +
  geom_text(check_overlap = TRUE, colour = 'blue')
  
```

This plot compares the resolution rate and the median time to resolve an issue
for each state. The horizontal dashed line represents the median interval 
between all states and the vertical line represents the general resolution rate.
The chart could be divided into four quadrants:

| Quadrant     | Resolution Rate  | Median interval  |
|--------------|------------------|------------------|
| Bottom left  | Low              | Fast             | 
| Bottom right | High             | Fast             |
| Upper left   | Low              | Slow             |
| Upper right  | High             | Slow             |

The best quadrant is the bottom right and the worst is the upper left.



# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the \
investigation. Were there features that strengthened each other in terms of \
looking at your feature(s) of interest?

The median time to resolve an issue doesn't have a direct correlation with the
resolution rate. Some states are fast to resolve an issue but have a small 
resolution rate (e.g. PR). Other states are fast and have a high resolution rate
(e.g. PB). Some states are slow and have a small resolution rate (e.g. DF).

### Were there any interesting or surprising interactions between features?

Some states have a huge difference between the elapsed time of resolved and 
not resolved issues.

------

# Final Plots and Summary

### Resolution rate per state
```{r echo=FALSE, Plot_One}

# sorting the state levels by the resolution rate
state_resolved$state <- factor(state_resolved$state,
                          levels(reorder(state_resolved$state, state_resolved$freq)))

breaks = c(resolutionRate, seq(0, 1, 0.25), max(state_resolved$freq))

ggplot(state_resolved, aes(x = state, y = freq)) +
  geom_bar(stat = "identity", fill = '#00BFC4') +
  annotate("text", x = 3.1, y = resolutionRate + 0.03, label = "Avg. resolution rate") +
  geom_hline(yintercept = resolutionRate, linetype = "dashed") +
  scale_y_continuous(labels = scales::percent, breaks = breaks) +
  xlab('State') +
  ylab('Resolution rate') +
  ggtitle("Resolution rate per state")
  
```

The state where the complaint was filed has a big impact on the chance to it be
resolved. The difference between the best resolution rate (in PB) and the worst
(in PR) is 33%.

### Median interval to resolve an issue per state
```{r echo=FALSE, Plot_Two}

# sorting the states by the median elapsed days 
state_ordered <- reorder(state_resolved_elapsedays$state, state_resolved_elapsedays$median)
state_resolved_elapsedays$state <- factor(state_resolved_elapsedays$state, levels(state_ordered))

breaks <- sort(c(medianElapsedDaysResolved, seq(0, 600, 150)))

ggplot(state_resolved_elapsedays, aes(x = state, y = median)) +
  geom_bar(stat = "identity", fill = '#00BFC4') +
  annotate("text", x = 2, y = medianElapsedDaysResolved + 20, label = "Median") +
  geom_hline(yintercept = medianElapsedDaysResolved, linetype = "dashed") +
  scale_y_continuous(breaks = breaks) +
  xlab('State') +
  ylab('Days') +
  ggtitle("Median interval to resolve an issue per state") 
```

Different states vary a lot the median time to resolve an issue. Acre (AC) and 
Distrito Federal (DF) have median time close to 600 days. While Rio de Janeiro (RJ)
and Piaui (PI) have the median time of 20 and 30 days respectively.

### Plot Three
```{r echo=FALSE, Plot_Three, warning=FALSE}

breaks = sort(c(24, 64, seq(100, 250, 50)))

ggplot(ds, aes(x = elapsedDays)) +
  geom_density(aes(color = resolved), alpha = 0.4) +
  scale_x_continuous(limits = c(0, 250), breaks = breaks) +
  scale_color_discrete(name = 'Resolved', labels=c('No', 'Yes')) +
  geom_vline(xintercept = 24, linetype = "dashed") +
  geom_vline(xintercept = 64, linetype = "dashed") +
  xlab('Elapsed days between regisration and close date') +
  ggtitle("Density curve of the elapsed days interval")
```

The chart above shows that the interval between 24 and 64 days has a greater
density of resolved issues, i.e. the resolution rate is greater,
as can be observed in the table below:

```{r echo=FALSE, Plot_Three_Aux_Table, warning=FALSE}

kable(elapseDaysIntervals_resolved[elapseDaysIntervals_resolved$resolved == 'Y', c(1, 4)])
```

This information will help to build a predictive model in a future work.

------

# Reflection

This exploratory analysis gave an overview of the performance of Procons in 
different states. For example, in Brasilia, capital of Brazil, the Procon has
a very poor performance in both the resolution rate (second worst) and
the time it took to resolve an issue (almost 2 years).

Ideas for the future:

* Use data from other years to analyze trends in data.
* Come up with an indicator of the quality of the Procon considering the resolution
rate and the time it takes to resolve the issue.
* Come up with an indicator for the companies.
* Come up with a predictive model to give the probability of an issue be resolved.

The worst data in the dataset was the name of the company because it came from
user input and have a lot of typos. As the focus of the analysis was to compare 
the performance of the states, this was not a big issue.

A feature missing in the dataset is the address of the Procon where the issue
was filed. This might help to identify the culprint for poor performance in the
states.


